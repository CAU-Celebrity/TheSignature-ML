{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "font_transfer(tensor_변환_error)__tensorflow2_변환중.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBq1aHD16drx"
      },
      "source": [
        "## font transfer (tensorflow version 1 사용) -> tensorflow 2로 변환 작업\n",
        "- 완료 X\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QgOJGJmwcl8",
        "outputId": "649003c7-c8d5-455a-b711-8d4403bea7c6"
      },
      "source": [
        "pip uninstall numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling numpy-1.19.5:\n",
            "  Would remove:\n",
            "    /usr/bin/f2py\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.7\n",
            "    /usr/local/lib/python3.7/dist-packages/numpy-1.19.5.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/numpy.libs/libgfortran-2e0d59d6.so.5.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/numpy.libs/libopenblasp-r0-09e95953.3.13.so\n",
            "    /usr/local/lib/python3.7/dist-packages/numpy.libs/libquadmath-2d0c479f.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/numpy.libs/libz-eb09ad1d.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/numpy/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled numpy-1.19.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "PtnFyETjq1LP",
        "outputId": "3ab7fe62-c39c-463b-bfaa-4600dee1d0ab"
      },
      "source": [
        "pip install numpy==1.19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/31/e2c3eda7afe7dab08e1f24767b8e38ff2f30dc82bd74aa3a5324c550366a/numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6MB 5.4MB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.19.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2dNpZMzjuGY",
        "outputId": "98aef0a4-4b2a-42e6-8164-16a607899f68"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "import json\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pgcdvYrxrA65",
        "outputId": "1e96100c-96a0-4ee8-b0a0-a9fc36cbc07f"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.4-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "455WdSw5s9b6",
        "outputId": "330113d0-fd4a-4b75-e3de-5b597c06d7d4"
      },
      "source": [
        "np.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.19.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFBtAIHJnR8h"
      },
      "source": [
        "# 데이터셋 이미지 처리 및 제작\n",
        "def crop_image(img):\n",
        "    image = np.array(img)\n",
        "    blur = cv2.GaussianBlur(image, ksize=(3,3), sigmaX=0)\n",
        "    ret, thresh1 = cv2.threshold(blur, 127, 255, cv2.THRESH_BINARY)\n",
        "    edged = cv2.Canny(blur, 10, 250)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
        "    closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n",
        "    contours, _ = cv2.findContours(closed.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    total = 0\n",
        "    contours_xy = np.array(contours)\n",
        "    x_min, x_max = 0,0\n",
        "    value = list()\n",
        "    for i in range(len(contours_xy)):\n",
        "      for j in range(len(contours_xy[i])):\n",
        "        value.append(contours_xy[i][j][0][0])\n",
        "        x_min = min(value)\n",
        "        x_max = max(value)\n",
        " \n",
        "    y_min, y_max = 0,0\n",
        "    value = list()\n",
        "    for i in range(len(contours_xy)):\n",
        "      for j in range(len(contours_xy[i])):\n",
        "        value.append(contours_xy[i][j][0][1])\n",
        "        y_min = min(value)\n",
        "        y_max = max(value)\n",
        "\n",
        "    x = x_min\n",
        "    y = y_min\n",
        "    w = x_max-x_min\n",
        "    h = y_max-y_min\n",
        "\n",
        "    return x, y, w, h\n",
        "\n",
        "def process_image(img, x, y, w, h, canvas_size):\n",
        "    new_width = 50\n",
        "    new_height = int(50 * h / w)\n",
        "    if new_height > 60:\n",
        "        new_height = 55\n",
        "        new_width = int(55 * w / h)\n",
        "    img = img.crop((x-1, y-1, x+w+1, y+h+1)).resize((new_width,new_height))\n",
        "    new_left = int((64 - img.width) / 2)\n",
        "    new_top = int((64 - img.height) / 2)\n",
        "    result = Image.new(\"L\", (canvas_size, canvas_size), color=255)\n",
        "    result.paste(img, (new_left, new_top))\n",
        "\n",
        "    return result\n",
        "\n",
        "def draw_single_char(ch, font, canvas_size, x_offset, y_offset):\n",
        "    img = Image.new(\"L\", (150, 150), color=255)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw.text((x_offset, y_offset), ch, fill=(0), font=font)\n",
        "    x, y, w, h = crop_image(img)\n",
        "    img = process_image(img, x, y, w, h, canvas_size)\n",
        "    return img\n",
        "\n",
        "\n",
        "def font2img(ttf, charset, char_size, canvas_size, x_offset, y_offset, folder):\n",
        "    global X_train, y_train\n",
        "    font = ImageFont.truetype(ttf, size=char_size)\n",
        "    count = 0\n",
        "    for c in charset:\n",
        "        e = draw_single_char(c, font, canvas_size, x_offset, y_offset)\n",
        "        if e:\n",
        "            e.save(folder+c+'.png')\n",
        "            # X_train.append(np.array(e))\n",
        "            # y_train.append(count)\n",
        "            count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwje8WkTncQs"
      },
      "source": [
        "path = './gdrive/MyDrive/hangul/ttf/'\n",
        "fonts = os.listdir(path)\n",
        "charset = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "char_size, canvas_size = 100, 64\n",
        "x_offset, y_offset = 10, 10\n",
        "label = 1\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "srcfont = fonts[0]\n",
        "font2img(path + srcfont, charset, char_size, canvas_size, x_offset, y_offset, 'src/')\n",
        "\n",
        "dstfont = fonts[1]\n",
        "font2img(path + dstfont, charset, char_size, canvas_size, x_offset, y_offset, 'dst/')\n",
        "\n",
        "# for font in fonts:\n",
        "#     font2img(path + font, charset, char_size, canvas_size, x_offset, y_offset)\n",
        "#     print('font#%02d 데이터셋 생성 완료' % (label))\n",
        "#     label += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITnTIglIp3ZG",
        "outputId": "6bb2760b-0e4a-41c9-adb2-9729a72b6941"
      },
      "source": [
        "np.array(Image.open('src/A.png')).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gv62ONJ696y"
      },
      "source": [
        "import matplotlib as plt\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# 이미지의 픽셀을 [0, 1]로 normalize하고 src-dst 이미지 연결\n",
        "def data_preprocess(path='', source_font='src', target_font='dst'):\n",
        "    source_path = source_font\n",
        "    source_fonts = list()\n",
        "    target_path = target_font\n",
        "    target_fonts = list()\n",
        "    files = os.listdir(source_path)\n",
        "    mid1 = np.zeros((64, 64, 1))\n",
        "    mid2 = np.zeros((64, 64, 1))   \n",
        "    \n",
        "    for file in files:\n",
        "        # src 이미지 로드\n",
        "        img1 = cv2.imread(source_path+'/'+file)\n",
        "        np1 = np.array(img1)\n",
        "        mid1 = np1[:, :, 0]\n",
        "        mid1 = mid1[:,:,np.newaxis]\n",
        "        source_fonts.append(mid1)\n",
        "\n",
        "        # dst 이미지 로드\n",
        "        img2 = cv2.imread(source_path+'/'+file)\n",
        "        np2 = np.array(img2)\n",
        "        mid2 = np2[:, :, 0]\n",
        "        mid2 = mid2[:,:,np.newaxis]\n",
        "        target_fonts.append(mid2)\n",
        "\n",
        "    source_fonts = np.array(source_fonts)\n",
        "    source_fonts = source_fonts.astype(np.float32)\n",
        "    source_fonts /= 255\n",
        "\n",
        "    target_fonts = np.array(target_fonts)\n",
        "    target_fonts = target_fonts.astype(np.float32)\n",
        "    target_fonts /= 255\n",
        "\n",
        "    return source_fonts, target_fonts\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, source_fonts, target_fonts, test_frac=0.4, val_frac=0.1, scale_func=None):\n",
        "        # train, validation, test dataset 제작\n",
        "        self.data_num = int(len(source_fonts))\n",
        "        self.val_num = int(self.data_num*(1-test_frac)*val_frac)\n",
        "        self.train_num = int(self.data_num * (1 - test_frac)) - self.val_num\n",
        "        self.test_num = self.data_num-self.val_num-self.train_num\n",
        "\n",
        "        self.train = {}\n",
        "        self.test = {}\n",
        "        self.valid = {}\n",
        "\n",
        "        self.train['source_font'] =source_fonts[:self.train_num]\n",
        "        self.valid['source_font'] =source_fonts[self.train_num: self.train_num+self.val_num]\n",
        "        self.test['source_font'] = source_fonts[self.train_num + self.val_num:]\n",
        "\n",
        "        self.train['target_font'] =target_fonts[:self.train_num]\n",
        "        self.valid['target_font'] =target_fonts[self.train_num: self.train_num+self.val_num]\n",
        "        self.test['target_font'] =target_fonts[self.train_num + self.val_num:]\n",
        "\n",
        "    def shuffle_data( self ):\n",
        "        idx = np.arange(self.train_num)\n",
        "        np.random.shuffle(idx)\n",
        "        self.train['source_font'], self.train['target_font'] = self.train['source_font'][idx], self.train['target_font'][idx]\n",
        "\n",
        "    def get_batches(self, batch_size):\n",
        "        batch_num = self.train_num // batch_size\n",
        "\n",
        "        for ii in range(0, batch_num * batch_size, batch_size):\n",
        "            source_font = self.train['source_font'][ii:ii+batch_size]\n",
        "            target_font = self.train['target_font'][ii:ii+batch_size]\n",
        "\n",
        "            yield source_font, target_font"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "RwXztEpsAFGw",
        "outputId": "f00fa51b-40d1-4235-8e44-842347546949"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
        "\n",
        "image_dim = (64, 64, 1)\n",
        "learning_rate = 0.005\n",
        "batch_size = 32\n",
        "element_num = batch_size*image_dim[0]*image_dim[1]*image_dim[2]\n",
        "epochs = 30\n",
        "beta1 = 0.9\n",
        "lambda_p = 1\n",
        "lambda_1 = 10\n",
        "lambda_2 = 1\n",
        "lambda_3 = 1\n",
        "lambda_4 = 30\n",
        "print_every = 1\n",
        "\n",
        "LAMDA = 100\n",
        "\n",
        "\n",
        "def generator(source_font, reuse=False, training=True):\n",
        "    model = tf.keras.Sequential()\n",
        "    model = tf.reshape(source_font, (-1, 64, 64, 1)) # reshape 안되면 train.ipyb의 discriminator 함수 참고\n",
        "    \n",
        "    # conv1: 64*64*1 -> 64*64*64\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    conv1 = model\n",
        "\n",
        "    # conv2: 128*128*64 -> 64*64*128\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    conv2 = model\n",
        "\n",
        "    # conv3: 64*64*128 -> 32*32*256\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    conv3 = model\n",
        "\n",
        "    # conv4: 32*32*256 -> 16*16*512\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    conv4 = model\n",
        "\n",
        "    # conv5: 16*16*512 -> 8*8*512\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # up6: 8*8*512 -> 16*16*512\n",
        "    model.add(layers.Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    up6 = model\n",
        "\n",
        "    # 16*16*512 + 16*16*512 -> 16*16*1024\n",
        "    model = tf.concat([conv4, up6], axis=3)\n",
        "\n",
        "    # conv6: 16*16*1024 -> 16*16*256\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    # up7: 16*16*256 -> 32*32*256\n",
        "    model.add(layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    up7 = model\n",
        "\n",
        "    # 32*32*256 + 32*32*256 -> 32*32*512\n",
        "    model = tf.concat([conv3, up7], axis=3)\n",
        "\n",
        "    # conv7: 32*32*512 -> 32*32*128\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # up8: 32*32*128 -> 64*64*128\n",
        "    model.add(layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    up8 = model\n",
        "\n",
        "    # 64*64*128 + 64*64*128 -> 64*64*256\n",
        "    model = tf.concat([conv2, up8], axis=3)\n",
        "\n",
        "    # conv8: 64*64*256 -> 64*64*64\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # up9: 64*64*64 -> 128*128*64\n",
        "    model.add(layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    up9 = model\n",
        "\n",
        "    # 128*128*64 + 128*128*64 -> 128*128*128\n",
        "    model = tf.concat([conv1, up9], axis=3)\n",
        "\n",
        "    # conv9: 128*128*128 -> 128*128*1\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2D(filters=1, kernel_size=3, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model = tf.math.sigmoid(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator(x, reuse=False):\n",
        "    # w_init = tf.contrib.layers.xavier_initializer()\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # conv1\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # conv2\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # conv3\n",
        "    model.add(layers.Conv2D(filters=1024, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # conv4\n",
        "    model.add(layers.Conv2D(filters=2048, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model = tf.reshape(model, (-1, 8*8*2048))\n",
        "    model.add(layers.Dense(1))\n",
        "    model = tf.math.sigmoid(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "class TransNN:\n",
        "    def __init__(self):\n",
        "        tf.reset_default_graph()\n",
        "\n",
        "    # 학습을 위한 모델 세팅\n",
        "    def model_setup(self):\n",
        "        self.target_fonts = tf.placeholder(\n",
        "            tf.float32, (None,  64, 64, 1), name='target_fonts')\n",
        "        self.source_fonts = tf.placeholder(\n",
        "            tf.float32, (None,  64, 64, 1), name='source_fonts')\n",
        "        self.target_fonts = tf.Variable()\n",
        "\n",
        "        self.generated_fonts = generator(self.source_fonts)\n",
        "        self.real_score = discriminator(self.target_fonts)\n",
        "        self.fake_score = discriminator(self.generated_fonts, reuse=True)\n",
        "\n",
        "    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    def model_loss(self):\n",
        "        # generator 학습을 위한 loss\n",
        "        gan_loss = loss_object(tf.ones_like(self.fake_score), self.fake_score)\n",
        "        l1_norm = tf.reduce_mean(tf.abs(self.target_fonts - self.generated_fonts))\n",
        "        v1_loss = gan_loss + lambda_4 * l1_norm\n",
        "        v1_loss /= element_num\n",
        "\n",
        "        # discriminator의 성능을 의한 loss\n",
        "        real_loss = loss_object(tf.ones_like(self.real_score), self.real_score)\n",
        "        generated_loss = loss_object(tf.zeros_like(self.fake_score), self.fake_score)\n",
        "        v2_loss = real_loss + generated_loss\n",
        "\n",
        "        self.generator_loss =  v1_loss  / batch_size \n",
        "        self.discriminator_loss = ( lambda_3 * v2_loss ) / batch_size\n",
        "\n",
        "        self.d_train_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "        self.g_train_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "    def train(self):\n",
        "        self.model_setup()\n",
        "        self.model_loss()\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        saver = tf.train.Saver()\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.allow_growth = True\n",
        "\n",
        "        with tf.Session(config=config) as sess:\n",
        "            sess.run(init)\n",
        "\n",
        "            for epoch_no in range(epochs):\n",
        "                dataset.shuffle_data()\n",
        "\n",
        "                batch_no = 0\n",
        "                for source_font, target_font in dataset.get_batches(batch_size):\n",
        "                    batch_no += 1\n",
        "                    print(\"Batch No: {}/{} \".format(batch_no, dataset.train_num // batch_size))\n",
        "\n",
        "                    # generator가 src_img로부터 이미지를 생성\n",
        "                    sess.run(self.generated_fonts, feed_dict={self.source_fonts: source_font, self.target_fonts: target_font})\n",
        "\n",
        "                    # discriminator 최적화(optimization)\n",
        "                    sess.run(self.d_train_opt, feed_dict={self.target_fonts: target_font, self.source_fonts: source_font})\n",
        "\n",
        "                    # generator 최적화 (optimization)\n",
        "                    sess.run(self.g_train_opt, feed_dict={self.target_fonts: target_font, self.source_fonts: source_font})\n",
        "\n",
        "                    if epoch_no % print_every == 0:\n",
        "                        train_loss_d = self.discriminator_loss.eval(\n",
        "                            {self.target_fonts: target_font, self.source_fonts: source_font})\n",
        "                        train_loss_g = self.generator_loss.eval(\n",
        "                            {self.source_fonts: source_font, self.target_fonts: target_font})\n",
        "\n",
        "                        print(\"Epoch {}/{}...\".format(epoch_no+1, epochs), \"Discriminator Loss: {:.8f}...\".format(train_loss_d), \"Generator Loss: {:.8f}\".format(train_loss_g))\n",
        "\n",
        "            saver.save(sess, './checkpoints/generator')\n",
        "\n",
        "    # 학습한 generator 모델 불러서 이미지 생성\n",
        "    def test(self):\n",
        "        # self.model_setup()\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        saver = tf.train.Saver()\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.allow_growth = True\n",
        "\n",
        "        with tf.Session(config=config) as sess:\n",
        "            sess.run(init)\n",
        "\n",
        "            saver = tf.train.import_meta_graph('./checkpoints/generator.meta')\n",
        "            saver.restore(sess, tf.train.latest_checkpoint('./checkpoints/'))\n",
        "            graph = tf.get_default_graph()\n",
        "            image_no = 0\n",
        "\n",
        "            for num in range(0, dataset.test_num, batch_size):\n",
        "                generated_fonts = sess.run(self.generated_fonts, feed_dict={\n",
        "                                           self.source_fonts: dataset.test['source_font'][num:num+batch_size], self.target_fonts: dataset.test['target_font'][num:num+batch_size]})\n",
        "                source_fonts = dataset.test['target_font'][num:num+batch_size]\n",
        "\n",
        "                for batch_no in range(min(batch_size, generated_fonts.shape[0])):\n",
        "                    generated_font = generated_fonts[batch_no]\n",
        "                    target_font = source_fonts[batch_no]\n",
        "\n",
        "                    mid = np.append(generated_font, generated_font, axis=2)\n",
        "                    mid = np.append(generated_font, mid, axis=2)\n",
        "                    mid = mid*255\n",
        "                    mid = mid.astype('uint8')\n",
        "                    img = Image.fromarray(mid)\n",
        "                    img.save(fp='./generated_fonts/generated_' +\n",
        "                             str(image_no) + '.jpg')\n",
        "\n",
        "                    mid[:, :, :] = target_font\n",
        "                    mid = mid*255\n",
        "                    mid = mid.astype('uint8')\n",
        "                    img = Image.fromarray(mid)\n",
        "                    img.save(fp='./generated_fonts/target_' +\n",
        "                             str(image_no)+'.jpg')\n",
        "\n",
        "                    image_no += 1\n",
        "\n",
        "\n",
        "# writer=tf.summary.FileWriter(r\"./gdrive/MyDrive/font_transfer/models\",tf.get_default_graph())\n",
        "# writer.close()\n",
        "source_fonts, target_fonts = data_preprocess()\n",
        "dataset = Dataset(source_fonts, target_fonts, test_frac=0.1, val_frac=0)\n",
        "\n",
        "net = TransNN()\n",
        "net.train()\n",
        "\n",
        "net.test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-092bafd7505d>:48: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-092bafd7505d>:49: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From <ipython-input-6-092bafd7505d>:31: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-6-092bafd7505d>:93: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-092bafd7505d>:190: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-092bafd7505d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-092bafd7505d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-092bafd7505d>\u001b[0m in \u001b[0;36mmodel_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmodel_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m#\bpix2pix cross_entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       p2p_cross_entropy = tf.reduce_sum(- lambda_p * np.multiply(self.target_fonts, tf.log(self.generated_fonts)\n\u001b[0m\u001b[1;32m    224\u001b[0m                                                        ) - np.multiply(1-self.target_fonts, tf.log(1-self.generated_fonts)))\n\u001b[1;32m    225\u001b[0m       \u001b[0mdiffrence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_fonts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_fonts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001b[0;32m--> 736\u001b[0;31m                               \" array.\".format(self.name))\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (target_fonts:0) to a numpy array."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLldz3X1pSC1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}